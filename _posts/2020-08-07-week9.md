---
layout: post
title: Week 9
---

This week was filled with template building and presentations. I had focused a lot on building indirect references and different logical modules, which meant that before this week I had only 11 templates. This week, I increased that number to 40 and expanded the categories of questions types from 2 to 8. 

Along with building these templates, I presented twice at group meetings. First, I presented my project at a lab meeting. I was very nervous about presenting, because it was the first time Michael Bernstein and some of the other interns were hearing extensively about my work, so I wanted to explain it in a sense that motivated my project. Although I spent rather a long time on developing the presentation, I think it went well, and it was a useful exercise for organizing the project in my mind. I also presented this week for the group meeting with other interns on three VQA modeling papers. I presented a VideoQA model that focused on hierarchy, a VideoQA model that focused on memory, and a ImageQA model that separated solving the problem into a question → graph problem and a graph → answering machine. It has been a while since I have done modeling work, so it was nice to start thinking in that way again. Our goal for the end of the summer will be to implement other models on my dataset, but I want to start thinking about how I can combine previous insights into a new model as well. 

Along with working on templates and presentations, I was attending other talks as well. I met one on one with Abubakar Abi, the creator of Gradio. We talked a lot about interpretability and integrating vision systems into healthcare, both of which greatly interest me. One big problem we discussed was communication between domain experts and developers, both for how already developed systems are functioning and for developing what problems to approach in the first place. I’m grateful he took the time to talk with me, and I really enjoyed the discussion. Another interesting meeting was with Deborah Raji  [1], who worked on the Gender Shades project. This project focused on algorithmic auditing, which means auditing the algorithms used by private companies, then pressuring them to address biases and inaccuracies in these algorithms. The specific issue they covered was disparities in facial recognition accuracy for men vs women and light skinned vs dark skinned people. They found that the facial recognition algorithm used by large companies such as Microsoft, IBM, and Face+ had much higher accuracy for white males than other groups, and dark skinned females had lower accuracy than other groups. Once they engaged with the algorithms used by these companies to find these disparities, the rest of their project focused on how to pressure companies into making meaningful changes. This involved both private pressure and public pressure. It was great to see them take the next step from recognizing the issue to implementing change.

For next week, now that we have templates, I will be editing and starting to design metrics and other details about the dataset. Although the amount of testing necessary is a bit overwhelming, I’m looking forward to shifting to a more design-based part of the project again. 

[1] https://scholar.google.com/citations?user=pzw1-J4AAAAJ
